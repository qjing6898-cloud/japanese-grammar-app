import streamlit as st
import pandas as pd
import google.generativeai as genai
from datetime import datetime
import json
import gspread
import pytz 
import time

# --- 1. é…ç½®ä½ çš„ AI ---
try:
    # ä» Streamlit Cloud Secrets å®‰å…¨è¯»å– Key
    GOOGLE_API_KEY = st.secrets["GOOGLE_API_KEY"]
    genai.configure(api_key=GOOGLE_API_KEY)
    model = genai.GenerativeModel('gemini-2.5-flash')
except KeyError:
    st.error("æ— æ³•è¯»å– Gemini API Keyã€‚è¯·åœ¨ Streamlit Cloud Secrets ä¸­æ£€æŸ¥ GOOGLE_API_KEY é…ç½®ã€‚")
except Exception as e:
    st.error(f"AI é…ç½®é”™è¯¯: {e}")

# --- 2. æ•°æ®åº“è¿æ¥é…ç½® (Google Sheets) ---
SHEET_TITLE = "Japanese_Grammar_History"
# âš ï¸âš ï¸âš ï¸ è¯·ä¿æŒä½ å·²ç»é…ç½®å¥½çš„ Google Sheets å®Œæ•´ç½‘å€ä¸å˜ï¼
SHEET_URL = "https://docs.google.com/spreadsheets/d/1xrXmiV5yEYIC4lDfgjk79vQDNVHYZugW6XUReZbHWjY/edit?gid=0#gid=0" 

@st.cache_resource(ttl=3600) # ç¼“å­˜è¿æ¥
def get_sheets_client():
    try:
        if "GCP_JSON_STRING" in st.secrets:
            key_dict = json.loads(st.secrets["GCP_JSON_STRING"])
            gc = gspread.service_account_from_dict(key_dict)
            return gc
        elif "gcp_service_account" in st.secrets:
            gcp_sa = st.secrets["gcp_service_account"]
            gc = gspread.service_account_from_dict(gcp_sa)
            return gc
        else:
            st.warning("æœªæ‰¾åˆ° Google Cloud å‡­è¯ (GCP_JSON_STRING)ã€‚")
            return None
    except Exception as e:
        st.error(f"Google Sheets è®¤è¯å¤±è´¥: {e}")
        return None

# ç¼“å­˜æ•°æ®è¯»å–
@st.cache_data(ttl=60) 
def load_history():
    """ä» Google Sheets è¯»å–å†å²è®°å½•"""
    gc = get_sheets_client()
    if not gc: return pd.DataFrame()
    
    try:
        spreadsheet = gc.open_by_url(SHEET_URL)
        worksheet = spreadsheet.sheet1
        df = pd.DataFrame(worksheet.get_all_records())
        
        if 'data_json' in df.columns:
            # è§£æ JSON å­—ç¬¦ä¸²
            df['data'] = df['data_json'].apply(lambda x: json.loads(x) if x else {})
            
            # ğŸŒŸ æ–°å¢ï¼šä» data ä¸­æå–è¯­è¨€å­—æ®µï¼Œå¦‚æœæ²¡æœ‰ï¼ˆè€æ•°æ®ï¼‰ï¼Œé»˜è®¤ä¸º "æ—¥è¯­"
            df['language'] = df['data'].apply(lambda x: x.get('language', 'æ—¥è¯­') if isinstance(x, dict) else 'æœªçŸ¥')
            
        return df.iloc[::-1] # å€’åº
    except gspread.exceptions.SpreadsheetNotFound:
        st.warning(f"Google è¡¨æ ¼ '{SHEET_TITLE}' ä¸å­˜åœ¨æˆ–æ— è®¿é—®æƒé™ã€‚")
        return pd.DataFrame()
    except Exception as e:
        st.error(f"åŠ è½½å†å²è®°å½•å¤±è´¥: {e}") 
        return pd.DataFrame()


def save_record(sentence, result_data):
    """å°†æ–°çš„è®°å½•å†™å…¥ Google Sheets"""
    gc = get_sheets_client()
    if not gc: return
    
    try:
        spreadsheet = gc.open_by_url(SHEET_URL)
        worksheet = spreadsheet.sheet1
        
        tz = pytz.timezone('Asia/Shanghai')
        timestamp_str = datetime.now(tz).strftime("%Y-%m-%d %H:%M:%S")

        new_row = [
            timestamp_str,
            sentence,
            json.dumps(result_data, ensure_ascii=False), 
            st.session_state.get('user_id', 'Unknown')
        ]
        
        if not worksheet.row_values(1):
            worksheet.append_row(['timestamp', 'sentence', 'data_json', 'user'])

        worksheet.append_row(new_row)
    except Exception as e:
        st.error(f"ä¿å­˜è®°å½•åˆ° Google Sheets å¤±è´¥: {e}")

# æ‰¹é‡åˆ é™¤å‡½æ•°
def delete_records_by_bulk(timestamps_list):
    """æ ¹æ®æ—¶é—´æˆ³åˆ—è¡¨æ‰¹é‡åˆ é™¤ Google Sheets ä¸­çš„è®°å½•"""
    gc = get_sheets_client()
    if not gc or not timestamps_list: return False
    
    try:
        spreadsheet = gc.open_by_url(SHEET_URL)
        worksheet = spreadsheet.sheet1
        
        timestamps_col = worksheet.col_values(1)
        
        rows_to_delete = []
        for ts in timestamps_list:
            try:
                row_index = timestamps_col.index(ts) + 1
                rows_to_delete.append(row_index)
            except ValueError:
                continue
        
        if not rows_to_delete:
            st.warning("æœªæ‰¾åˆ°è¦åˆ é™¤çš„è®°å½•ã€‚")
            return False

        # æ ¸å¿ƒï¼šæŒ‰è¡Œå·ä»å¤§åˆ°å°æ’åº
        rows_to_delete.sort(reverse=True)
        
        success_count = 0
        for row_idx in rows_to_delete:
            worksheet.delete_rows(row_idx)
            success_count += 1
        
        st.success(f"æˆåŠŸåˆ é™¤ {success_count} æ¡è®°å½•ã€‚")
        return True
            
    except Exception as e:
        st.error(f"æ‰¹é‡åˆ é™¤å¤±è´¥: {e}")
        return False

# åˆ—åæ˜ å°„ (é€šç”¨åŒ–ï¼Œä¸å†å±€é™äºæ—¥è¯­)
COLUMN_MAPPING = {
    "word": "å•è¯/åŸæ–‡",
    "reading": "å‘éŸ³ (éŸ³æ ‡/æ‹¼éŸ³/ç½—é©¬éŸ³)",
    "pos_meaning": "è¯æ€§ / å«ä¹‰", 
    "grammar": "è¯­æ³•è¯´æ˜",
    "standard": "åŸå‹/æ ‡å‡†å½¢å¼"
}


# --- è¾…åŠ©å‡½æ•°ï¼šçŠ¶æ€åŒæ­¥ ---

def update_individual_selection(ts):
    """å½“å•ä¸ªå¤é€‰æ¡†è¢«ç‚¹å‡»æ—¶è°ƒç”¨"""
    checkbox_key = f"sel_{ts}"
    is_checked = st.session_state[checkbox_key] 
    st.session_state.delete_selections[ts] = is_checked
    if not is_checked and st.session_state.select_all:
        st.session_state.select_all = False

def update_selections():
    """å½“ç‚¹å‡»å…¨é€‰æ—¶è°ƒç”¨"""
    select_all_state = st.session_state.select_all
    
    # é‡æ–°è·å–å½“å‰ç­›é€‰åçš„æ•°æ®
    history_df = load_history() 
    
    # 1. åº”ç”¨è¯­è¨€ç­›é€‰
    filter_lang = st.session_state.get('filter_language', None)
    if filter_lang:
        history_df = history_df[history_df['language'] == filter_lang]
        
    # 2. åº”ç”¨æœç´¢å…³é”®è¯ç­›é€‰
    search_query = st.session_state.get('search_query', '')
    if search_query:
        filtered_df = history_df[
            history_df['sentence'].str.contains(search_query, case=False, na=False) | 
            (history_df['data'].astype(str).str.contains(search_query, case=False, na=False))
        ]
    else:
        filtered_df = history_df
        
    for ts in filtered_df['timestamp']:
        st.session_state.delete_selections[ts] = select_all_state
        if f"sel_{ts}" in st.session_state:
            st.session_state[f"sel_{ts}"] = select_all_state

def bulk_delete_callback(timestamps_to_delete):
    """åˆ é™¤æŒ‰é’®çš„å›è°ƒå‡½æ•°"""
    if not timestamps_to_delete:
        st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€æ¡è®°å½•è¿›è¡Œåˆ é™¤ã€‚")
        return

    if delete_records_by_bulk(timestamps_to_delete):
        st.session_state.select_all = False
        st.session_state.delete_selections = {}
        time.sleep(1) 
        load_history.clear()
        # st.rerun() # å›è°ƒç»“æŸåä¼šè‡ªåŠ¨åˆ·æ–°


# --- 4. æ ¸å¿ƒåŠŸèƒ½ï¼šAI åˆ†æ (å…¨è¯­ç§å‡çº§ç‰ˆ) ---
def analyze_with_ai(text):
    # ğŸŒŸ æç¤ºè¯å¤§å‡çº§ï¼šæ”¯æŒè‡ªåŠ¨è¯†åˆ«è¯­è¨€
    prompt = f"""
    è¯·ä½œä¸ºä¸€ä½ç²¾é€šå…¨çƒè¯­è¨€çš„è¯­è¨€å­¦ä¸“å®¶ï¼Œåˆ†æä»¥ä¸‹æ–‡æœ¬ï¼š
    â€œ{text}â€
    
    è¯·æ‰§è¡Œä»¥ä¸‹æ­¥éª¤ï¼š
    1. **è‡ªåŠ¨è¯†åˆ«** è¾“å…¥æ–‡æœ¬çš„è¯­è¨€ï¼ˆä¾‹å¦‚ï¼šæ—¥è¯­ã€è‹±è¯­ã€æ³•è¯­ã€éŸ©è¯­ã€ä¸­æ–‡ã€è¥¿ç­ç‰™è¯­ç­‰ï¼‰ã€‚
    2. å°†æ–‡æœ¬ç¿»è¯‘æˆæµç•…çš„ **ä¸­æ–‡ï¼ˆç®€ä½“ï¼‰**ã€‚
    3. åˆ†ææ–‡æœ¬ä¸­çš„è¯­æ°”ã€æƒ¯ç”¨è¯­ã€è¯­æ³•ç»“æ„æˆ–æ–­å¥é€»è¾‘ã€‚
    4. å¯¹æ–‡æœ¬è¿›è¡Œé€è¯/é€ç»“æ„æ‹†è§£åˆ†æã€‚

    è¯·è¾“å‡ºä¸€ä¸ªä¸¥æ ¼çš„ JSON æ ¼å¼å¯¹è±¡ï¼ŒåŒ…å«ä»¥ä¸‹å››ä¸ªå­—æ®µï¼š
    1. "language": è¯†åˆ«å‡ºçš„è¯­è¨€åç§° (å­—ç¬¦ä¸²ï¼Œä¾‹å¦‚ "è‹±è¯­", "æ—¥è¯­")ã€‚
    2. "translation": ä¸­æ–‡ç¿»è¯‘ã€‚
    3. "nuances": è¯¦ç»†çš„è¯­æ³•ç¬”è®°ã€æƒ¯ç”¨è¯­è§£é‡Šæˆ–æ–‡åŒ–èƒŒæ™¯è¯´æ˜ã€‚
    4. "structure": ä¸€ä¸ªåˆ—è¡¨ï¼ŒåŒ…å«é€è¯æ‹†è§£ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«ï¼š
       - "word": åŸæ–‡å•è¯/è¯ç»„
       - "reading": å‘éŸ³æ³¨éŸ³ (è‹±è¯­è¯·æä¾›IPAéŸ³æ ‡ï¼Œæ—¥è¯­æä¾›ç½—é©¬éŸ³ï¼Œä¸­æ–‡æä¾›æ‹¼éŸ³ï¼Œå…¶ä»–è¯­è¨€æä¾›ç›¸åº”çš„æ‹‰ä¸åŒ–å‘éŸ³)
       - "pos_meaning": è¯æ€§åŠä¸­æ–‡å«ä¹‰
       - "grammar": ç®€çŸ­è¯­æ³•è¯´æ˜ (æ—¶æ€ã€å˜ä½ç­‰)
       - "standard": åŸå‹/æ ‡å‡†å½¢å¼ (å¦‚åŠ¨è¯åŸå½¢)

    ç¤ºä¾‹ JSON ç»“æ„:
    {{
        "language": "æ—¥è¯­",
        "translation": "...",
        "nuances": "...",
        "structure": [
            {{ "word": "...", "reading": "...", "pos_meaning": "...", "grammar": "...", "standard": "..." }}
        ]
    }}

    è¯·ç¡®ä¿è¾“å‡ºæ˜¯åˆæ³•çš„ JSON æ ¼å¼ï¼Œä¸è¦åŒ…å« Markdown æ ‡è®°ã€‚
    """
    
    try:
        response = model.generate_content(prompt)
        clean_text = response.text.replace('```json', '').replace('```', '').strip()
        result = json.loads(clean_text)
        
        # ç®€å•éªŒè¯ç»“æ„
        if "structure" not in result or "translation" not in result:
             return {"error": "AIè¿”å›æ ¼å¼ä¸å®Œæ•´", "structure": []}
            
        return result
        
    except Exception as e:
        return {"error": f"AIåˆ†æå¤±è´¥: {e}", "structure": []}

# --- 3. é¡µé¢é…ç½® ---
st.set_page_config(
    page_title="å…¨èƒ½è¯­è¨€ä¼´ä¾£ AIç‰ˆ",
    page_icon="ğŸŒ",
    layout="centered",
    initial_sidebar_state="collapsed"
)

# éšè—å³ä¸Šè§’èœå•
hide_menu_style = """
        <style>
        #MainMenu {visibility: hidden;}
        header {visibility: hidden;}
        footer {visibility: hidden;}
        /* å¼ºåˆ¶ st.table è‡ªåŠ¨æ¢è¡Œ */
        td { white-space: normal !important; word-wrap: break-word !important; }
        /* ä¼˜åŒ–ç¿»è¯‘æ–‡æœ¬æ ·å¼ */
        .translation-box {
            background-color: #f0f2f6;
            padding: 15px;
            border-radius: 10px;
            margin-bottom: 20px;
            font-size: 16px;
            color: #31333F;
        }
        .grammar-box {
            background-color: #e8f4f9;
            padding: 15px;
            border-radius: 10px;
            margin-top: 10px;
            border-left: 5px solid #4da6ff;
        }
        /* è¯­è¨€æ ‡ç­¾æ ·å¼ */
        .lang-tag {
            background-color: #ffe6e6;
            color: #cc0000;
            padding: 2px 8px;
            border-radius: 12px;
            font-size: 12px;
            font-weight: bold;
            margin-bottom: 5px;
            display: inline-block;
        }
        </style>
        """
st.markdown(hide_menu_style, unsafe_allow_html=True)


if 'user_id' not in st.session_state:
    st.session_state['user_id'] = 'ç”¨æˆ·A'

# --- 5. ç•Œé¢ UI ---
st.title("ğŸŒ å…¨èƒ½è¯­è¨€ä¼´ä¾£ (AI Pro)")

st.session_state['user_id'] = st.sidebar.text_input("è¾“å…¥ä½ çš„æ˜µç§°:", value=st.session_state['user_id'])

# è¾“å…¥åŒº
with st.container():
    sentence = st.text_area("è¾“å…¥ä»»ä½•è¯­è¨€:", height=80, placeholder="ä¾‹å¦‚ï¼šHello world / Bonjour / æ±ºã‚ã¡ã‚ƒã„ã¾ã™ã‹ã‚‰ã­")
    
    if st.button("âœ¨ AI æ·±åº¦è§£æ", type="primary"):
        if not sentence:
            st.warning("è¯·è¾“å…¥å¥å­")
        else:
            with st.spinner('AI æ­£åœ¨è¯†åˆ«è¯­è¨€å¹¶è§£æ (çº¦éœ€5ç§’)...'):
                ai_result = analyze_with_ai(sentence)
                
                if "error" in ai_result:
                    st.error(ai_result["error"])
                else:
                    save_record(sentence, ai_result)
                    load_history.clear()
                    
                    st.success(f"è§£æå®Œæˆï¼è¯†åˆ«ä¸ºï¼š{ai_result.get('language', 'æœªçŸ¥')}")
                    
                    st.markdown(f"""
                    <div class="translation-box">
                        <span class="lang-tag">{ai_result.get('language', 'é€šç”¨')}</span>
                        <b> ğŸ‡¨ğŸ‡³ ä¸­æ–‡ç¿»è¯‘ï¼š</b><br>{ai_result.get('translation', '')}
                    </div>
                    """, unsafe_allow_html=True)

                    st.markdown("### ğŸ§© ç»“æ„æ‹†è§£")
                    df = pd.DataFrame(ai_result.get('structure', []))
                    if not df.empty:
                        df_display = df.rename(columns=COLUMN_MAPPING)
                        st.table(df_display)

                    st.markdown(f"""
                    <div class="grammar-box">
                        <b>ğŸ’¡ è¯­æ³•ç¬”è®°ä¸æ–‡åŒ–èƒŒæ™¯ï¼š</b><br>
                        {ai_result.get('nuances', 'æ— ç‰¹æ®Šè¯´æ˜').replace(chr(10), '<br>')}
                    </div>
                    """, unsafe_allow_html=True)

st.divider()

# --- 6. å­¦ä¹ è¶³è¿¹ (å«è¯­è¨€ç­›é€‰ã€æœç´¢ä¸æ‰¹é‡åˆ é™¤) ---
st.subheader("ğŸ“š å­¦ä¹ è¶³è¿¹")

# åˆå§‹åŒ– session_state
if 'select_all' not in st.session_state:
    st.session_state.select_all = False
if 'delete_selections' not in st.session_state:
    st.session_state.delete_selections = {}
if 'search_query' not in st.session_state:
    st.session_state.search_query = ''
if 'filter_language' not in st.session_state:
    st.session_state.filter_language = None  # None è¡¨ç¤ºæ˜¾ç¤ºå…¨éƒ¨

# åŠ è½½æ•°æ®
history_df = load_history()

if not history_df.empty and 'timestamp' in history_df.columns:
    
    # ğŸŒŸ 1. è‡ªåŠ¨ç”Ÿæˆè¯­è¨€ç­›é€‰æŒ‰é’®
    # è·å–å†å²è®°å½•ä¸­å‡ºç°è¿‡çš„æ‰€æœ‰è¯­è¨€
    available_languages = history_df['language'].unique().tolist()
    
    if len(available_languages) > 0:
        st.markdown("**æŒ‰è¯­è¨€ç­›é€‰ï¼š**")
        
        # åŠ¨æ€åˆ›å»ºåˆ—æ¥æ”¾ç½®æŒ‰é’® (é˜²æ­¢æŒ‰é’®æ¢è¡Œå¤ªä¸‘)
        # è¿™é‡Œä½¿ç”¨ä¸€ä¸ªç®€å•çš„æ°´å¹³å¸ƒå±€å®¹å™¨
        cols = st.columns(len(available_languages) + 1)
        
        # å®šä¹‰ä¸€ä¸ªå›è°ƒå‡½æ•°æ¥å¤„ç†æŒ‰é’®ç‚¹å‡»
        def set_lang_filter(lang):
            if st.session_state.filter_language == lang:
                st.session_state.filter_language = None # å†æ¬¡ç‚¹å‡»å–æ¶ˆç­›é€‰
            else:
                st.session_state.filter_language = lang
            # é‡ç½®å…¨é€‰çŠ¶æ€ï¼Œå› ä¸ºåˆ—è¡¨å˜äº†
            st.session_state.select_all = False 
            st.session_state.delete_selections = {}

        # æ¸²æŸ“æŒ‰é’®
        # æ¸²æŸ“ "å…¨éƒ¨" çŠ¶æ€çš„æŒ‡ç¤º (å¯é€‰ï¼Œè¿™é‡Œé€šè¿‡æŒ‰é’®é¢œè‰²åŒºåˆ†)
        for i, lang in enumerate(available_languages):
            # æ£€æŸ¥å½“å‰è¯­è¨€æ˜¯å¦è¢«é€‰ä¸­ï¼Œç»™äºˆä¸åŒçš„è§†è§‰æç¤º (é€šè¿‡ type='primary' æˆ– 'secondary')
            btn_type = "primary" if st.session_state.filter_language == lang else "secondary"
            if cols[i].button(lang, key=f"filter_btn_{lang}", type=btn_type):
                set_lang_filter(lang)
                st.rerun()

    st.markdown("---")

    # ğŸŒŸ 2. æ‰§è¡Œå¤šé‡è¿‡æ»¤ (è¯­è¨€ + æœç´¢)
    filtered_df = history_df.copy()

    # (A) è¯­è¨€è¿‡æ»¤
    if st.session_state.filter_language:
        filtered_df = filtered_df[filtered_df['language'] == st.session_state.filter_language]

    # (B) æœç´¢è¿‡æ»¤
    search_query = st.text_input(
        "ğŸ” æœç´¢å†å²è®°å½•:", 
        placeholder="è¾“å…¥åŸæ–‡æˆ–ç¿»è¯‘å…³é”®è¯...",
        key='search_query'
    )
    
    if search_query:
        filtered_df = filtered_df[
            filtered_df['sentence'].str.contains(search_query, case=False, na=False) | 
            (filtered_df['data'].astype(str).str.contains(search_query, case=False, na=False))
        ]

    # --- æ‰¹é‡åˆ é™¤æŒ‰é’®ã€å…¨é€‰/åé€‰å’Œå¤„ç†é€»è¾‘ ---
    if not filtered_df.empty:
        col_select, col_delete_btn, col_placeholder = st.columns([0.15, 0.35, 0.5])

        col_select.checkbox(
            "å…¨é€‰",
            key="select_all",
            on_change=update_selections
        )

        timestamps_to_delete = [
            ts for ts, is_checked in st.session_state.delete_selections.items() 
            if is_checked and ts in filtered_df['timestamp'].values
        ]
        
        col_delete_btn.button(
            "ğŸ—‘ï¸ æ‰¹é‡åˆ é™¤é€‰ä¸­é¡¹", 
            type="primary", 
            key="bulk_delete_main_btn",
            on_click=bulk_delete_callback,
            args=(timestamps_to_delete,)
        )

    # --- æ˜¾ç¤ºè®°å½• ---
    if filtered_df.empty:
        if search_query or st.session_state.filter_language:
            st.info("æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„è®°å½•ã€‚")
        else:
            st.info("æ²¡æœ‰å­¦ä¹ è®°å½•ã€‚")
    else:
        for index, item in filtered_df.iterrows():
            timestamp = item['timestamp']
            display_sentence = item['sentence'][:20] + '...' if len(item['sentence']) > 20 else item['sentence']
            lang_label = item.get('language', 'æœªçŸ¥')
            
            col_check, col_expander = st.columns([0.05, 0.95])
            
            with col_check:
                checkbox_key = f"sel_{timestamp}"
                if checkbox_key not in st.session_state:
                    st.session_state[checkbox_key] = st.session_state.delete_selections.get(timestamp, False)

                st.checkbox(
                    label="", 
                    key=checkbox_key, 
                    value=st.session_state.delete_selections.get(timestamp, False),
                    on_change=update_individual_selection,
                    args=(timestamp,),
                    label_visibility="hidden"
                )

            with col_expander:
                with st.expander(f"ğŸ•’ {timestamp} | [{lang_label}] {display_sentence}"):
                    
                    st.markdown(f"**æ“ä½œäººï¼š** {item['user']}")
                    st.markdown(f"**åŸæ–‡ï¼š** {item['sentence']}")
                    
                    data = item.get('data', {})
                    if data and "structure" in data:
                        st.markdown("---")
                        st.markdown(f"**ç¿»è¯‘ï¼š** {data.get('translation', 'æ— ')}")
                        
                        st.markdown(f"##### {lang_label}ç»“æ„æ‹†è§£")
                        df_hist = pd.DataFrame(data['structure'])
                        st.table(df_hist.rename(columns=COLUMN_MAPPING))
                        
                        if data.get('nuances'):
                             st.info(f"ğŸ’¡ ç¬”è®°ï¼š{data.get('nuances')}")
                    else:
                        st.warning("âš ï¸ æ—§æ•°æ®æˆ–è§£æå¤±è´¥ï¼Œæ— æ³•æ˜¾ç¤ºè¯¦ç»†å†…å®¹")

else:
    st.info("è¿˜æ²¡æœ‰å­¦ä¹ è®°å½•ï¼Œå¿«å»è¾“å…¥ç¬¬ä¸€å¥å¤–è¯­å§ï¼")
