import streamlit as st
import pandas as pd
import google.generativeai as genai
from datetime import datetime
import json
import gspread
import pytz 
# import gspread_dataframe # Sheets ä¾èµ–

# --- 1. é…ç½®ä½ çš„ AI ---
try:
    # ä» Streamlit Cloud Secrets å®‰å…¨è¯»å– Key
    GOOGLE_API_KEY = st.secrets["GOOGLE_API_KEY"]
    genai.configure(api_key=GOOGLE_API_KEY)
    model = genai.GenerativeModel('gemini-2.5-flash')
except KeyError:
    st.error("æ— æ³•è¯»å– Gemini API Keyã€‚è¯·åœ¨ Streamlit Cloud Secrets ä¸­æ£€æŸ¥ GOOGLE_API_KEY é…ç½®ã€‚")
except Exception as e:
    st.error(f"AI é…ç½®é”™è¯¯: {e}")

# --- 2. æ•°æ®åº“è¿æ¥é…ç½® (Google Sheets) ---
SHEET_TITLE = "Japanese_Grammar_History"
# âš ï¸âš ï¸âš ï¸ è¯·ä¿æŒä½ å·²ç»é…ç½®å¥½çš„ Google Sheets å®Œæ•´ç½‘å€ä¸å˜ï¼
SHEET_URL = "https://docs.google.com/spreadsheets/d/1xrXmiV5yEYIC4lDfgjk79vQDNVHYZugW6XUReZbHWjY/edit?gid=0#gid=0" 

@st.cache_resource(ttl=3600) # ç¼“å­˜è¿æ¥ï¼Œé¿å…é‡å¤è®¤è¯
def get_sheets_client():
    try:
        # å°è¯•ä» Secrets ä¸­è¯»å–åŸæ ·ç²˜è´´çš„ JSON å­—ç¬¦ä¸²
        if "GCP_JSON_STRING" in st.secrets:
            # å¿…é¡»å¯¼å…¥ json åº“æ‰èƒ½è§£æå­—ç¬¦ä¸²
            key_dict = json.loads(st.secrets["GCP_JSON_STRING"])
            gc = gspread.service_account_from_dict(key_dict)
            return gc
        
        # å…¼å®¹æ—§çš„é…ç½®æ–¹å¼ (å¤‡ç”¨)
        elif "gcp_service_account" in st.secrets:
            gcp_sa = st.secrets["gcp_service_account"]
            gc = gspread.service_account_from_dict(gcp_sa)
            return gc
            
        else:
            st.warning("æœªæ‰¾åˆ° Google Cloud å‡­è¯ (GCP_JSON_STRING)ã€‚")
            return None
    except Exception as e:
        st.error(f"Google Sheets è®¤è¯å¤±è´¥: {e}")
        return None

def load_history():
    """ä» Google Sheets è¯»å–å†å²è®°å½•ï¼Œå¹¶å°† JSON å­—ç¬¦ä¸²è§£æå› Python å¯¹è±¡"""
    gc = get_sheets_client()
    if not gc: return pd.DataFrame()
    
    try:
        spreadsheet = gc.open_by_url(SHEET_URL)
        worksheet = spreadsheet.sheet1
        # è¯»å–è¡¨æ ¼æ‰€æœ‰å†…å®¹
        df = pd.DataFrame(worksheet.get_all_records())
        
        if 'data_json' in df.columns:
            # ğŸŒŸ å…³é”®æ­¥éª¤ï¼šå°† data_json è¿™ä¸€åˆ—çš„ JSON å­—ç¬¦ä¸²è§£ææˆ Python åˆ—è¡¨/å­—å…¸
            # ä½¿ç”¨ .apply(json.loads) æ¥è§£ææ¯ä¸€è¡Œ
            df['data'] = df['data_json'].apply(lambda x: json.loads(x) if x else [])
            df = df.drop(columns=['data_json']) # ç§»é™¤åŸå§‹ JSON å­—ç¬¦ä¸²åˆ—
            
        return df.iloc[::-1] # å€’åºï¼Œæœ€æ–°è®°å½•åœ¨å‰
    except gspread.exceptions.SpreadsheetNotFound:
        st.warning(f"Google è¡¨æ ¼ '{SHEET_TITLE}' ä¸å­˜åœ¨æˆ–æ— è®¿é—®æƒé™ã€‚è¯·æ£€æŸ¥å…±äº«è®¾ç½®ã€‚")
        return pd.DataFrame()
    except Exception as e:
        st.error(f"åŠ è½½å†å²è®°å½•å¤±è´¥: {e}")
        return pd.DataFrame()


def save_record(sentence, result_data):
    # å°†æ–°çš„è®°å½•å†™å…¥ Google Sheets
    gc = get_sheets_client()
    if not gc: return
    
    try:
        spreadsheet = gc.open_by_url(SHEET_URL)
        worksheet = spreadsheet.sheet1
        
        # ä½¿ç”¨ä¸œå…«åŒºæ—¶é—´ (æ—¶åŒºä¿®å¤)
        tz = pytz.timezone('Asia/Shanghai')
        timestamp_str = datetime.now(tz).strftime("%Y-%m-%d %H:%M:%S")

        # å‡†å¤‡è¦å†™å…¥çš„æ•°æ®è¡Œ
        new_row = [
            timestamp_str,
            sentence,
            # å†™å…¥æ—¶ä»ç„¶ä½¿ç”¨ JSON å­—ç¬¦ä¸²æ ¼å¼
            json.dumps(result_data, ensure_ascii=False), 
            st.session_state.get('user_id', 'Unknown')
        ]
        
        # ç¡®ä¿è¡¨æ ¼æœ‰åˆ—å¤´ï¼Œå¦‚æœè¡¨æ ¼ä¸ºç©ºï¼Œå…ˆå†™å…¥åˆ—å¤´
        if not worksheet.row_values(1):
            worksheet.append_row(['timestamp', 'sentence', 'data_json', 'user'])

        worksheet.append_row(new_row)
    except Exception as e:
        st.error(f"ä¿å­˜è®°å½•åˆ° Google Sheets å¤±è´¥: {e}")

# --- 3. é¡µé¢é…ç½® ---
st.set_page_config(
    page_title="æ—¥è¯­è¯­æ³•ä¼´ä¾£ AIç‰ˆ (äº‘åŒæ­¥)",
    page_icon="ğŸ‡¯ğŸ‡µ",
    layout="centered",
    initial_sidebar_state="collapsed"
)

# éšè—å³ä¸Šè§’èœå•çš„æ ·å¼
hide_menu_style = """
        <style>
        #MainMenu {visibility: hidden;}
        header {visibility: hidden;}
        footer {visibility: hidden;}
        </style>
        """
st.markdown(hide_menu_style, unsafe_allow_html=True)


# åˆå§‹åŒ– session_state
if 'user_id' not in st.session_state:
    st.session_state['user_id'] = 'ç”¨æˆ·A'

# --- 4. æ ¸å¿ƒåŠŸèƒ½ï¼šAI åˆ†æ (å·²ä¼˜åŒ–é”™è¯¯å¤„ç†) ---
def analyze_with_ai(text):
    prompt = f"""
    è¯·ä½œä¸ºä¸€ä½ä¸“ä¸šçš„æ—¥è¯­è€å¸ˆï¼Œåˆ†æä»¥ä¸‹æ—¥è¯­å¥å­ï¼š
    â€œ{text}â€
    
    è¯·è¾“å‡ºä¸€ä¸ªä¸¥æ ¼çš„ JSON æ ¼å¼åˆ—è¡¨ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
    - "word": åŸæ–‡å•è¯
    - "reading": ç½—é©¬éŸ³ (Romaji)
    - "pos_meaning": è¯æ€§åŠä¸­æ–‡å«ä¹‰ (ä¾‹å¦‚ï¼šåŠ¨è¯ / å†³å®š)
    - "grammar": è¯¦ç»†è¯­æ³•è¯´æ˜ (ä¾‹å¦‚ï¼šã¦ã—ã¾ã†çš„å£è¯­ç¼©ç•¥å½¢å¼)
    - "standard": æ ‡å‡†å½¢å¼/ä¹¦é¢è¯­ (ä¾‹å¦‚ï¼šã¦ã—ã¾ã„ã¾ã™)

    è¯·ç¡®ä¿è¾“å‡ºæ˜¯åˆæ³•çš„ JSON æ•°ç»„æ ¼å¼ï¼Œä¸è¦åŒ…å« Markdown æ ‡è®°ã€‚
    """
    
    try:
        response = model.generate_content(prompt)
        clean_text = response.text.replace('```json', '').replace('```', '').strip()
        
        # å°è¯•è§£æ JSON
        result = json.loads(clean_text)
        
        # ç¡®ä¿è¿”å›ç»“æœæ˜¯ä¸€ä¸ªéç©ºåˆ—è¡¨
        if not isinstance(result, list) or not result:
            return [{"word": "é”™è¯¯", "pos_meaning": "AIæœªèƒ½è¿”å›æœ‰æ•ˆçš„è¯­æ³•è§£æç»“æœã€‚è¯·å°è¯•ä½¿ç”¨ä¸åŒçš„å¥å­æˆ–æ£€æŸ¥ç½‘ç»œè¿æ¥ã€‚"}]
            
        return result
        
    except json.JSONDecodeError as e:
        error_msg = f"AIè¿”å›æ ¼å¼é”™è¯¯ï¼Œè¯·ç¨åå†è¯•ã€‚åŸå§‹é”™è¯¯ï¼š{e}"
        if len(response.text) > 200:
             error_msg += f" ... AIè¿”å›å†…å®¹ç‰‡æ®µ: {response.text[:200]}..."
        return [{"word": "é”™è¯¯", "pos_meaning": error_msg}]

    except Exception as e:
        return [{"word": "é”™è¯¯", "pos_meaning": f"AIåˆ†æå¤±è´¥: {e}"}]

# --- 5. ç•Œé¢ UI ---
st.title("ğŸ‡¯ğŸ‡µ æ—¥è¯­è¯­æ³•ä¼´ä¾£ (äº‘åŒæ­¥ AI Pro)")

# ä¾§è¾¹æ ï¼Œç”¨äºè¾“å…¥æ˜µç§°
st.session_state['user_id'] = st.sidebar.text_input("è¾“å…¥ä½ çš„æ˜µç§° (ç”¨äºå†å²è®°å½•):", value=st.session_state['user_id'])

# å®šä¹‰è¡¨æ ¼åˆ—é…ç½®
COLUMN_CONFIG = {
    "word": "éƒ¨åˆ† (æ—¥æ–‡)",
    "reading": "è¯»éŸ³ (ç½—é©¬å­—)",
    "pos_meaning": st.column_config.TextColumn(
        "å“è¯ / æ„å‘³", # ğŸŒŸ å¼€å¯è‡ªåŠ¨æ¢è¡Œ
        width="medium"
    ), 
    "grammar": st.column_config.TextColumn(
        "è¯­æ³•è¯´æ˜", # ğŸŒŸ å¼€å¯è‡ªåŠ¨æ¢è¡Œ
        width="large"
    ),
    "standard": "æ ‡å‡†å½¢å¼"
}


# è¾“å…¥åŒº
with st.container():
    sentence = st.text_area("è¾“å…¥æ—¥è¯­:", height=80, placeholder="ä¾‹å¦‚ï¼šæ±ºã‚ã¡ã‚ƒã„ã¾ã™ã‹ã‚‰ã­")
    
    if st.button("âœ¨ AI æ·±åº¦è§£æ", type="primary"):
        if not sentence:
            st.warning("è¯·è¾“å…¥å¥å­")
        else:
            with st.spinner('AI è€å¸ˆæ­£åœ¨åˆ†æè¯­æ³• (çº¦éœ€3ç§’)...'):
                # è°ƒç”¨ AI
                result_data = analyze_with_ai(sentence)
                
                # å†™å…¥ Google Sheets (åªæœ‰æˆåŠŸè§£ææ‰å†™å…¥)
                if result_data and 'word' in result_data[0] and 'é”™è¯¯' not in result_data[0]['word']:
                    save_record(sentence, result_data)
                
                # æ˜¾ç¤ºç»“æœ
                st.success("è§£æå®Œæˆï¼")
                st.markdown("### ğŸ“ æ·±åº¦æ‹†è§£")
                
                df = pd.DataFrame(result_data)
                
                # ğŸŒŸ åº”ç”¨è‡ªåŠ¨æ¢è¡Œé…ç½®åˆ°å½“å‰è§£æç»“æœ
                st.dataframe(
                    df, 
                    column_config=COLUMN_CONFIG,
                    use_container_width=True,
                    hide_index=True
                )

st.divider()

# å†å²è®°å½•
st.subheader("ğŸ“š å­¦ä¹ è¶³è¿¹ (äº‘åŒæ­¥)")

# ä» Google Sheets è¯»å–å†å²è®°å½•å¹¶æ˜¾ç¤º
history_df = load_history()

if not history_df.empty and 'timestamp' in history_df.columns:
    
    # ğŸŒŸ è¿­ä»£å†å²è®°å½•ï¼Œä½¿ç”¨ expander æ˜¾ç¤ºå®Œæ•´è§£æå†…å®¹
    for index, item in history_df.iterrows():
        # é™åˆ¶å¥å­æ˜¾ç¤ºé•¿åº¦
        display_sentence = item['sentence'][:20] + '...' if len(item['sentence']) > 20 else item['sentence']
        
        with st.expander(f"ğŸ•’ {item['timestamp']} | ç”¨æˆ·: {item['user']} | å¥å­: {display_sentence}"):
            st.info(item['sentence'])
            
            # åªæœ‰ data å­—æ®µå­˜åœ¨ä¸”ä¸ä¸ºç©ºæ—¶æ‰æ˜¾ç¤ºè¡¨æ ¼
            if item['data']:
                df_hist = pd.DataFrame(item['data'])
                st.markdown("##### è¯¦ç»†è§£æç»“æœ")
                # ğŸŒŸ åº”ç”¨è‡ªåŠ¨æ¢è¡Œé…ç½®åˆ°å†å²è®°å½•è¡¨æ ¼
                st.dataframe(
                    df_hist, 
                    column_config=COLUMN_CONFIG,
                    use_container_width=True, 
                    hide_index=True
                )
            else:
                st.warning("æœ¬æ¬¡æŸ¥è¯¢æ— æœ‰æ•ˆçš„è§£ææ•°æ®ã€‚")
    
else:
    st.info("å†å²è®°å½•åŠ è½½å¤±è´¥æˆ–è¡¨æ ¼ä¸ºç©ºã€‚è¯·æ£€æŸ¥ Google Sheets å…±äº«è®¾ç½®å’Œé…ç½®ã€‚")
