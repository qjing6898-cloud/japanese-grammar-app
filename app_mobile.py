import streamlit as st
import pandas as pd
import google.generativeai as genai
from datetime import datetime
import json
import gspread
import pytz 
import time

# --- 1. é…ç½®ä½ çš„ AI ---
try:
    # ä» Streamlit Cloud Secrets å®‰å…¨è¯»å– Key
    GOOGLE_API_KEY = st.secrets["GOOGLE_API_KEY"]
    genai.configure(api_key=GOOGLE_API_KEY)
    model = genai.GenerativeModel('gemini-2.5-flash')
except KeyError:
    st.error("æ— æ³•è¯»å– Gemini API Keyã€‚è¯·åœ¨ Streamlit Cloud Secrets ä¸­æ£€æŸ¥ GOOGLE_API_KEY é…ç½®ã€‚")
except Exception as e:
    st.error(f"AI é…ç½®é”™è¯¯: {e}")

# --- 2. æ•°æ®åº“è¿æ¥é…ç½® (Google Sheets) ---
SHEET_TITLE = "Japanese_Grammar_History"
# âš ï¸âš ï¸âš ï¸ è¯·ä¿æŒä½ å·²ç»é…ç½®å¥½çš„ Google Sheets å®Œæ•´ç½‘å€ä¸å˜ï¼
SHEET_URL = "https://docs.google.com/spreadsheets/d/1xrXmiV5yEYIC4lDfgjk79vQDNVHYZugW6XUReZbHWjY/edit?gid=0#gid=0" 

@st.cache_resource(ttl=3600) # ç¼“å­˜è¿æ¥
def get_sheets_client():
    try:
        if "GCP_JSON_STRING" in st.secrets:
            key_dict = json.loads(st.secrets["GCP_JSON_STRING"])
            gc = gspread.service_account_from_dict(key_dict)
            return gc
        elif "gcp_service_account" in st.secrets:
            gcp_sa = st.secrets["gcp_service_account"]
            gc = gspread.service_account_from_dict(gcp_sa)
            return gc
        else:
            st.warning("æœªæ‰¾åˆ° Google Cloud å‡­è¯ (GCP_JSON_STRING)ã€‚")
            return None
    except Exception as e:
        st.error(f"Google Sheets è®¤è¯å¤±è´¥: {e}")
        return None

# ç¼“å­˜æ•°æ®è¯»å–ï¼Œé¿å…é¢‘ç¹è°ƒç”¨ API è§¦å‘é…é¢é™åˆ¶
@st.cache_data(ttl=60) 
def load_history():
    """ä» Google Sheets è¯»å–å†å²è®°å½•"""
    gc = get_sheets_client()
    if not gc: return pd.DataFrame()
    
    try:
        spreadsheet = gc.open_by_url(SHEET_URL)
        worksheet = spreadsheet.sheet1
        df = pd.DataFrame(worksheet.get_all_records())
        
        if 'data_json' in df.columns:
            df['data'] = df['data_json'].apply(lambda x: json.loads(x) if x else {})
            
        return df.iloc[::-1] # å€’åº
    except gspread.exceptions.SpreadsheetNotFound:
        st.warning(f"Google è¡¨æ ¼ '{SHEET_TITLE}' ä¸å­˜åœ¨æˆ–æ— è®¿é—®æƒé™ã€‚")
        return pd.DataFrame()
    except Exception as e:
        st.error(f"åŠ è½½å†å²è®°å½•å¤±è´¥: {e}") 
        return pd.DataFrame()


def save_record(sentence, result_data):
    """å°†æ–°çš„è®°å½•å†™å…¥ Google Sheets"""
    gc = get_sheets_client()
    if not gc: return
    
    try:
        spreadsheet = gc.open_by_url(SHEET_URL)
        worksheet = spreadsheet.sheet1
        
        tz = pytz.timezone('Asia/Shanghai')
        timestamp_str = datetime.now(tz).strftime("%Y-%m-%d %H:%M:%S")

        new_row = [
            timestamp_str,
            sentence,
            json.dumps(result_data, ensure_ascii=False), 
            st.session_state.get('user_id', 'Unknown')
        ]
        
        if not worksheet.row_values(1):
            worksheet.append_row(['timestamp', 'sentence', 'data_json', 'user'])

        worksheet.append_row(new_row)
    except Exception as e:
        st.error(f"ä¿å­˜è®°å½•åˆ° Google Sheets å¤±è´¥: {e}")

# ğŸŒŸ æ‰¹é‡åˆ é™¤å‡½æ•°
def delete_records_by_bulk(timestamps_list):
    """æ ¹æ®æ—¶é—´æˆ³åˆ—è¡¨æ‰¹é‡åˆ é™¤ Google Sheets ä¸­çš„è®°å½•"""
    gc = get_sheets_client()
    if not gc or not timestamps_list: return False
    
    try:
        spreadsheet = gc.open_by_url(SHEET_URL)
        worksheet = spreadsheet.sheet1
        
        timestamps_col = worksheet.col_values(1)
        
        rows_to_delete = []
        for ts in timestamps_list:
            try:
                row_index = timestamps_col.index(ts) + 1
                rows_to_delete.append(row_index)
            except ValueError:
                continue
        
        if not rows_to_delete:
            st.warning("æœªæ‰¾åˆ°è¦åˆ é™¤çš„è®°å½•ã€‚")
            return False

        # æ ¸å¿ƒï¼šæŒ‰è¡Œå·ä»å¤§åˆ°å°æ’åºï¼Œç¡®ä¿å…ˆåˆ é™¤é åçš„è¡Œï¼Œé˜²æ­¢è¡Œç´¢å¼•é”™ä¹±
        rows_to_delete.sort(reverse=True)
        
        success_count = 0
        for row_idx in rows_to_delete:
            worksheet.delete_rows(row_idx)
            success_count += 1
        
        st.success(f"æˆåŠŸåˆ é™¤ {success_count} æ¡è®°å½•ã€‚")
        return True
            
    except Exception as e:
        st.error(f"æ‰¹é‡åˆ é™¤å¤±è´¥: {e}")
        return False

# åˆ—åæ˜ å°„
COLUMN_MAPPING = {
    "word": "å•è¯",
    "reading": "è¯»éŸ³",
    "pos_meaning": "å“è¯ / æ„å‘³", 
    "grammar": "è¯­æ³•è¯´æ˜",
    "standard": "æ ‡å‡†å½¢å¼"
}


# --- è¾…åŠ©å‡½æ•°ï¼šçŠ¶æ€åŒæ­¥ ---

def update_individual_selection(ts):
    """å½“å•ä¸ªå¤é€‰æ¡†è¢«ç‚¹å‡»æ—¶è°ƒç”¨ï¼Œæ›´æ–°å…¨å±€é€‰ä¸­å­—å…¸ï¼Œå¹¶æ£€æŸ¥æ˜¯å¦éœ€è¦å–æ¶ˆâ€œå…¨é€‰â€çŠ¶æ€"""
    checkbox_key = f"sel_{ts}"
    is_checked = st.session_state[checkbox_key] 
    
    st.session_state.delete_selections[ts] = is_checked

    # å¦‚æœå–æ¶ˆå‹¾é€‰äº†ä»»ä¸€è®°å½•ï¼Œåˆ™å–æ¶ˆâ€œå…¨é€‰â€çŠ¶æ€
    if not is_checked and st.session_state.select_all:
        st.session_state.select_all = False

def update_selections():
    """å½“ç‚¹å‡»å…¨é€‰æ—¶è°ƒç”¨ï¼Œå¼ºåˆ¶æ›´æ–°æ‰€æœ‰å¯è§è®°å½•çš„é€‰ä¸­çŠ¶æ€"""
    select_all_state = st.session_state.select_all
    
    # è·å–å½“å‰ç­›é€‰åçš„æ•°æ®èŒƒå›´
    history_df = load_history() 
    search_query = st.session_state.get('search_query', '')
    if search_query:
        filtered_df = history_df[history_df['sentence'].str.contains(search_query, case=False, na=False)]
    else:
        filtered_df = history_df
        
    # éå†å½“å‰ç­›é€‰åçš„æ‰€æœ‰æ—¶é—´æˆ³
    for ts in filtered_df['timestamp']:
        # 1. æ›´æ–°å…¨å±€é€‰ä¸­å­—å…¸
        st.session_state.delete_selections[ts] = select_all_state
        # 2. å¼ºåˆ¶æ›´æ–°å¤é€‰æ¡†çš„ Streamlit å†…éƒ¨çŠ¶æ€ (ç¡®ä¿ visual update)
        st.session_state[f"sel_{ts}"] = select_all_state


# --- 4. æ ¸å¿ƒåŠŸèƒ½ï¼šAI åˆ†æ (å‡çº§ç‰ˆ) ---
def analyze_with_ai(text):
    prompt = f"""
    è¯·ä½œä¸ºä¸€ä½ä¸“ä¸šçš„æ—¥è¯­è€å¸ˆï¼Œåˆ†æä»¥ä¸‹æ—¥è¯­å¥å­ï¼š
    â€œ{text}â€
    
    è¯·è¾“å‡ºä¸€ä¸ªä¸¥æ ¼çš„ JSON æ ¼å¼å¯¹è±¡ï¼ŒåŒ…å«ä»¥ä¸‹ä¸‰ä¸ªå­—æ®µï¼š
    1. "translation": å¥å­çš„ä¸­æ–‡ç¿»è¯‘ã€‚
    2. "nuances": ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œè¯¦ç»†è§£é‡Šå¥å­ä¸­çš„æƒ¯ç”¨è¯­ã€è¯­æ°”ã€æ–­å¥é€»è¾‘æˆ–ç‰¹å®šè¯­æ³•åº”ç”¨ï¼ˆç±»ä¼¼â€œè¯­æ³•ç¬”è®°â€ï¼‰ã€‚
    3. "structure": ä¸€ä¸ªåˆ—è¡¨ï¼ŒåŒ…å«é€è¯æ‹†è§£ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«ï¼š
       - "word": åŸæ–‡å•è¯
       - "reading": ç½—é©¬éŸ³
       - "pos_meaning": è¯æ€§åŠä¸­æ–‡å«ä¹‰
       - "grammar": ç®€çŸ­è¯­æ³•è¯´æ˜
       - "standard": æ ‡å‡†å½¢å¼

    ç¤ºä¾‹ JSON ç»“æ„:
    {{
        "translation": "ä¸­æ–‡ç¿»è¯‘...",
        "nuances": "è¿™é‡Œä½¿ç”¨äº†...çš„æƒ¯ç”¨å‹...",
        "structure": [
            {{ "word": "...", "reading": "...", "pos_meaning": "...", "grammar": "...", "standard": "..." }}
        ]
    }}

    è¯·ç¡®ä¿è¾“å‡ºæ˜¯åˆæ³•çš„ JSON æ ¼å¼ï¼Œä¸è¦åŒ…å« Markdown æ ‡è®°ã€‚
    """
    
    try:
        response = model.generate_content(prompt)
        clean_text = response.text.replace('```json', '').replace('```', '').strip()
        result = json.loads(clean_text)
        
        if "structure" not in result or "translation" not in result:
             return {"error": "AIè¿”å›æ ¼å¼ä¸å®Œæ•´", "structure": []}
            
        return result
        
    except Exception as e:
        return {"error": f"AIåˆ†æå¤±è´¥: {e}", "structure": []}

# --- 3. é¡µé¢é…ç½® ---
st.set_page_config(
    page_title="æ—¥è¯­è¯­æ³•ä¼´ä¾£ AIç‰ˆ (äº‘åŒæ­¥)",
    page_icon="ğŸ‡¯ğŸ‡µ",
    layout="centered",
    initial_sidebar_state="collapsed"
)

# éšè—å³ä¸Šè§’èœå•
hide_menu_style = """
        <style>
        #MainMenu {visibility: hidden;}
        header {visibility: hidden;}
        footer {visibility: hidden;}
        /* å¼ºåˆ¶ st.table è‡ªåŠ¨æ¢è¡Œ */
        td { white-space: normal !important; word-wrap: break-word !important; }
        /* ä¼˜åŒ–ç¿»è¯‘æ–‡æœ¬æ ·å¼ */
        .translation-box {
            background-color: #f0f2f6;
            padding: 15px;
            border-radius: 10px;
            margin-bottom: 20px;
            font-size: 16px;
            color: #31333F;
        }
        .grammar-box {
            background-color: #e8f4f9;
            padding: 15px;
            border-radius: 10px;
            margin-top: 10px;
            border-left: 5px solid #4da6ff;
        }
        </style>
        """
st.markdown(hide_menu_style, unsafe_allow_html=True)


if 'user_id' not in st.session_state:
    st.session_state['user_id'] = 'ç”¨æˆ·A'

# --- 5. ç•Œé¢ UI ---
st.title("ğŸ‡¯ğŸ‡µ æ—¥è¯­è¯­æ³•ä¼´ä¾£ (Pro Max)")

st.session_state['user_id'] = st.sidebar.text_input("è¾“å…¥ä½ çš„æ˜µç§°:", value=st.session_state['user_id'])

# è¾“å…¥åŒº
with st.container():
    sentence = st.text_area("è¾“å…¥æ—¥è¯­:", height=80, placeholder="ä¾‹å¦‚ï¼šæ±ºã‚ã¡ã‚ƒã„ã¾ã™ã‹ã‚‰ã­")
    
    if st.button("âœ¨ AI æ·±åº¦è§£æ", type="primary"):
        if not sentence:
            st.warning("è¯·è¾“å…¥å¥å­")
        else:
            with st.spinner('AI è€å¸ˆæ­£åœ¨ç¿»è¯‘å’Œæ‹†è§£ (çº¦éœ€5ç§’)...'):
                ai_result = analyze_with_ai(sentence)
                
                if "error" in ai_result:
                    st.error(ai_result["error"])
                else:
                    save_record(sentence, ai_result)
                    
                    st.success("è§£æå®Œæˆï¼")
                    
                    st.markdown(f"""
                    <div class="translation-box">
                        <b>ğŸ‡¨ğŸ‡³ ä¸­æ–‡ç¿»è¯‘ï¼š</b><br>{ai_result.get('translation', '')}
                    </div>
                    """, unsafe_allow_html=True)

                    st.markdown("### ğŸ§© ç»“æ„æ‹†è§£")
                    df = pd.DataFrame(ai_result.get('structure', []))
                    if not df.empty:
                        df_display = df.rename(columns=COLUMN_MAPPING)
                        st.table(df_display)

                    st.markdown(f"""
                    <div class="grammar-box">
                        <b>ğŸ’¡ è¯­æ³•ç¬”è®°ä¸æƒ¯ç”¨è¯­ï¼š</b><br>
                        {ai_result.get('nuances', 'æ— ç‰¹æ®Šè¯´æ˜').replace(chr(10), '<br>')}
                    </div>
                    """, unsafe_allow_html=True)

st.divider()

# --- 6. å­¦ä¹ è¶³è¿¹ (å«æœç´¢ä¸æ‰¹é‡åˆ é™¤) ---
st.subheader("ğŸ“š å­¦ä¹ è¶³è¿¹")

# åˆå§‹åŒ– session_state
if 'select_all' not in st.session_state:
    st.session_state.select_all = False
if 'delete_selections' not in st.session_state:
    st.session_state.delete_selections = {}
if 'search_query' not in st.session_state:
    st.session_state.search_query = ''


# åŠ è½½æ•°æ®
history_df = load_history()

if not history_df.empty and 'timestamp' in history_df.columns:
    
    # æœç´¢æ¡†æ¶
    search_query = st.text_input(
        "ğŸ” æœç´¢å†å²è®°å½• (è¾“å…¥å…³é”®è¯):", 
        placeholder="è¾“å…¥æ—¥è¯­æˆ–ç¿»è¯‘å…³é”®è¯...",
        key='search_query' # ç»‘å®šåˆ° session state
    )
    
    # æ‰§è¡Œè¿‡æ»¤
    if search_query:
        filtered_df = history_df[history_df['sentence'].str.contains(search_query, case=False, na=False)]
    else:
        filtered_df = history_df

    # --- æ‰¹é‡åˆ é™¤æŒ‰é’®ã€å…¨é€‰/åé€‰å’Œå¤„ç†é€»è¾‘ ---
    if not filtered_df.empty:
        col_select, col_delete_btn, col_placeholder = st.columns([0.15, 0.35, 0.5])

        # ğŸŒŸ å…¨é€‰/åé€‰å¤é€‰æ¡†
        col_select.checkbox(
            "å…¨é€‰",
            key="select_all",
            on_change=update_selections
        )

        if col_delete_btn.button("ğŸ—‘ï¸ æ‰¹é‡åˆ é™¤é€‰ä¸­é¡¹", type="primary", key="bulk_delete_main_btn"):
            
            # æ”¶é›†æ‰€æœ‰è¢«é€‰ä¸­çš„æ—¶é—´æˆ³
            timestamps_to_delete = [
                ts for ts, is_checked in st.session_state.delete_selections.items() 
                if is_checked and ts in filtered_df['timestamp'].values
            ]

            if timestamps_to_delete:
                with st.spinner("æ‰¹é‡åˆ é™¤ä¸­ï¼Œè¯·ç¨å€™..."):
                    if delete_records_by_bulk(timestamps_to_delete):
                        # åˆ é™¤æˆåŠŸåï¼Œé‡ç½®çŠ¶æ€ã€æ¸…é™¤ç¼“å­˜å¹¶åˆ·æ–°
                        st.session_state.select_all = False
                        st.session_state.delete_selections = {}
                        
                        time.sleep(1) 
                        load_history.clear()
                        st.rerun() 
                    else:
                        st.error("æ‰¹é‡åˆ é™¤æ“ä½œå¤±è´¥ã€‚")
            else:
                st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€æ¡è®°å½•è¿›è¡Œåˆ é™¤ã€‚")

    # --- æ˜¾ç¤ºè®°å½• ---
    if filtered_df.empty and search_query:
        st.info(f"æ²¡æœ‰æ‰¾åˆ°ä¸ '{search_query}' åŒ¹é…çš„è®°å½•ã€‚")
    elif filtered_df.empty:
        st.info("æ²¡æœ‰å­¦ä¹ è®°å½•ã€‚")
    else:
        # éå†æ˜¾ç¤º
        for index, item in filtered_df.iterrows():
            timestamp = item['timestamp']
            display_sentence = item['sentence'][:20] + '...' if len(item['sentence']) > 20 else item['sentence']
            
            col_check, col_expander = st.columns([0.05, 0.95])
            
            with col_check:
                checkbox_key = f"sel_{timestamp}"
                
                st.checkbox(
                    label="", 
                    key=checkbox_key, 
                    value=st.session_state.delete_selections.get(timestamp, False),
                    on_change=update_individual_selection,
                    args=(timestamp,),
                    label_visibility="hidden"
                )

            with col_expander:
                with st.expander(f"ğŸ•’ {timestamp} | {display_sentence}"):
                    
                    st.markdown(f"**æ“ä½œäººï¼š** {item['user']}")
                    st.markdown(f"**åŸæ–‡ï¼š** {item['sentence']}")
                    
                    data = item.get('data', {})
                    if data and "structure" in data:
                        st.markdown("---")
                        st.markdown(f"**ç¿»è¯‘ï¼š** {data.get('translation', 'æ— ')}")
                        
                        st.markdown("##### ç»“æ„æ‹†è§£")
                        df_hist = pd.DataFrame(data['structure'])
                        st.table(df_hist.rename(columns=COLUMN_MAPPING))
                        
                        if data.get('nuances'):
                             st.info(f"ğŸ’¡ ç¬”è®°ï¼š{data.get('nuances')}")
                    else:
                        st.warning("âš ï¸ æ—§æ•°æ®æˆ–è§£æå¤±è´¥ï¼Œæ— æ³•æ˜¾ç¤ºè¯¦ç»†å†…å®¹")

else:
    st.info("è¿˜æ²¡æœ‰å­¦ä¹ è®°å½•ï¼Œå¿«å»è§£æç¬¬ä¸€å¥æ—¥è¯­å§ï¼")
