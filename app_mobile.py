import streamlit as st
import pandas as pd
import google.generativeai as genai
from datetime import datetime
import json
import gspread
import pytz 
import time

# --- 1. é…ç½®ä½ çš„ AI ---
try:
    # ä» Streamlit Cloud Secrets å®‰å…¨è¯»å– Key
    GOOGLE_API_KEY = st.secrets["GOOGLE_API_KEY"]
    genai.configure(api_key=GOOGLE_API_KEY)
    model = genai.GenerativeModel('gemini-2.5-flash')
except KeyError:
    st.error("æ— æ³•è¯»å– Gemini API Keyã€‚è¯·åœ¨ Streamlit Cloud Secrets ä¸­æ£€æŸ¥ GOOGLE_API_KEY é…ç½®ã€‚")
except Exception as e:
    st.error(f"AI é…ç½®é”™è¯¯: {e}")

# --- 2. æ•°æ®åº“è¿æ¥é…ç½® (Google Sheets) ---
SHEET_TITLE = "Japanese_Grammar_History"
# âš ï¸âš ï¸âš ï¸ è¯·ä¿æŒä½ å·²ç»é…ç½®å¥½çš„ Google Sheets å®Œæ•´ç½‘å€ä¸å˜ï¼
SHEET_URL = "https://docs.google.com/spreadsheets/d/1xrXmiV5yEYIC4lDfgjk79vQDNVHYZugW6XUReZbHWjY/edit?gid=0#gid=0" 

@st.cache_resource(ttl=3600) # ç¼“å­˜è¿æ¥
def get_sheets_client():
    try:
        if "GCP_JSON_STRING" in st.secrets:
            key_dict = json.loads(st.secrets["GCP_JSON_STRING"])
            gc = gspread.service_account_from_dict(key_dict)
            return gc
        elif "gcp_service_account" in st.secrets:
            gcp_sa = st.secrets["gcp_service_account"]
            gc = gspread.service_account_from_dict(gcp_sa)
            return gc
        else:
            st.warning("æœªæ‰¾åˆ° Google Cloud å‡­è¯ (GCP_JSON_STRING)ã€‚")
            return None
    except Exception as e:
        st.error(f"Google Sheets è®¤è¯å¤±è´¥: {e}")
        return None

def load_history():
    """ä» Google Sheets è¯»å–å†å²è®°å½•"""
    gc = get_sheets_client()
    if not gc: return pd.DataFrame()
    
    try:
        spreadsheet = gc.open_by_url(SHEET_URL)
        worksheet = spreadsheet.sheet1
        df = pd.DataFrame(worksheet.get_all_records())
        
        if 'data_json' in df.columns:
            # è§£æ JSON å­—ç¬¦ä¸²
            df['data'] = df['data_json'].apply(lambda x: json.loads(x) if x else {})
            # ç§»é™¤åŸå§‹ JSON å­—ç¬¦ä¸²åˆ— (ä¿ç•™å…¶ä»–åˆ—ä»¥ä¾¿ç­›é€‰)
            # df = df.drop(columns=['data_json']) 
            
        return df.iloc[::-1] # å€’åº
    except gspread.exceptions.SpreadsheetNotFound:
        st.warning(f"Google è¡¨æ ¼ '{SHEET_TITLE}' ä¸å­˜åœ¨æˆ–æ— è®¿é—®æƒé™ã€‚")
        return pd.DataFrame()
    except Exception as e:
        st.error(f"åŠ è½½å†å²è®°å½•å¤±è´¥: {e}")
        return pd.DataFrame()


def save_record(sentence, result_data):
    """å°†æ–°çš„è®°å½•å†™å…¥ Google Sheets"""
    gc = get_sheets_client()
    if not gc: return
    
    try:
        spreadsheet = gc.open_by_url(SHEET_URL)
        worksheet = spreadsheet.sheet1
        
        tz = pytz.timezone('Asia/Shanghai')
        timestamp_str = datetime.now(tz).strftime("%Y-%m-%d %H:%M:%S")

        new_row = [
            timestamp_str,
            sentence,
            json.dumps(result_data, ensure_ascii=False), 
            st.session_state.get('user_id', 'Unknown')
        ]
        
        if not worksheet.row_values(1):
            worksheet.append_row(['timestamp', 'sentence', 'data_json', 'user'])

        worksheet.append_row(new_row)
    except Exception as e:
        st.error(f"ä¿å­˜è®°å½•åˆ° Google Sheets å¤±è´¥: {e}")

def delete_record(timestamp_to_delete):
    """æ ¹æ®æ—¶é—´æˆ³åˆ é™¤ Google Sheets ä¸­çš„è®°å½•"""
    gc = get_sheets_client()
    if not gc: return False
    
    try:
        spreadsheet = gc.open_by_url(SHEET_URL)
        worksheet = spreadsheet.sheet1
        
        # è·å–ç¬¬ä¸€åˆ—ï¼ˆæ—¶é—´æˆ³åˆ—ï¼‰çš„æ‰€æœ‰å€¼
        timestamps = worksheet.col_values(1)
        
        # æŸ¥æ‰¾è¦åˆ é™¤çš„æ—¶é—´æˆ³æ‰€åœ¨çš„è¡Œå· (æ³¨æ„ï¼šgspreadè¡Œå·ä»1å¼€å§‹ï¼Œä¸”åˆ—è¡¨ç´¢å¼•ä»0å¼€å§‹)
        try:
            # timestampsåˆ—è¡¨åŒ…å«è¡¨å¤´ï¼Œæ‰€ä»¥ç´¢å¼•è¦å°å¿ƒå¤„ç†
            row_index = timestamps.index(timestamp_to_delete) + 1
            worksheet.delete_rows(row_index)
            return True
        except ValueError:
            st.error("æœªæ‰¾åˆ°å¯¹åº”è®°å½•ï¼Œå¯èƒ½å·²è¢«åˆ é™¤ã€‚")
            return False
            
    except Exception as e:
        st.error(f"åˆ é™¤å¤±è´¥: {e}")
        return False

# --- 3. é¡µé¢é…ç½® ---
st.set_page_config(
    page_title="æ—¥è¯­è¯­æ³•ä¼´ä¾£ AIç‰ˆ (äº‘åŒæ­¥)",
    page_icon="ğŸ‡¯ğŸ‡µ",
    layout="centered",
    initial_sidebar_state="collapsed"
)

# éšè—å³ä¸Šè§’èœå•
hide_menu_style = """
        <style>
        #MainMenu {visibility: hidden;}
        header {visibility: hidden;}
        footer {visibility: hidden;}
        /* å¼ºåˆ¶ st.table è‡ªåŠ¨æ¢è¡Œ */
        td { white-space: normal !important; word-wrap: break-word !important; }
        /* ä¼˜åŒ–ç¿»è¯‘æ–‡æœ¬æ ·å¼ */
        .translation-box {
            background-color: #f0f2f6;
            padding: 15px;
            border-radius: 10px;
            margin-bottom: 20px;
            font-size: 16px;
            color: #31333F;
        }
        .grammar-box {
            background-color: #e8f4f9;
            padding: 15px;
            border-radius: 10px;
            margin-top: 10px;
            border-left: 5px solid #4da6ff;
        }
        </style>
        """
st.markdown(hide_menu_style, unsafe_allow_html=True)


if 'user_id' not in st.session_state:
    st.session_state['user_id'] = 'ç”¨æˆ·A'

# --- 4. æ ¸å¿ƒåŠŸèƒ½ï¼šAI åˆ†æ (å‡çº§ç‰ˆ) ---
def analyze_with_ai(text):
    # ğŸŒŸ æç¤ºè¯å‡çº§ï¼šå¢åŠ ç¿»è¯‘å’Œè¯­æ³•åº”ç”¨
    prompt = f"""
    è¯·ä½œä¸ºä¸€ä½ä¸“ä¸šçš„æ—¥è¯­è€å¸ˆï¼Œåˆ†æä»¥ä¸‹æ—¥è¯­å¥å­ï¼š
    â€œ{text}â€
    
    è¯·è¾“å‡ºä¸€ä¸ªä¸¥æ ¼çš„ JSON æ ¼å¼å¯¹è±¡ï¼ŒåŒ…å«ä»¥ä¸‹ä¸‰ä¸ªå­—æ®µï¼š
    1. "translation": å¥å­çš„ä¸­æ–‡ç¿»è¯‘ã€‚
    2. "nuances": ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œè¯¦ç»†è§£é‡Šå¥å­ä¸­çš„æƒ¯ç”¨è¯­ã€è¯­æ°”ã€æ–­å¥é€»è¾‘æˆ–ç‰¹å®šè¯­æ³•åº”ç”¨ï¼ˆç±»ä¼¼â€œè¯­æ³•ç¬”è®°â€ï¼‰ã€‚
    3. "structure": ä¸€ä¸ªåˆ—è¡¨ï¼ŒåŒ…å«é€è¯æ‹†è§£ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«ï¼š
       - "word": åŸæ–‡å•è¯
       - "reading": ç½—é©¬éŸ³
       - "pos_meaning": è¯æ€§åŠä¸­æ–‡å«ä¹‰
       - "grammar": ç®€çŸ­è¯­æ³•è¯´æ˜
       - "standard": æ ‡å‡†å½¢å¼

    ç¤ºä¾‹ JSON ç»“æ„:
    {{
        "translation": "ä¸­æ–‡ç¿»è¯‘...",
        "nuances": "è¿™é‡Œä½¿ç”¨äº†...çš„æƒ¯ç”¨å‹...",
        "structure": [
            {{ "word": "...", "reading": "...", "pos_meaning": "...", "grammar": "...", "standard": "..." }}
        ]
    }}

    è¯·ç¡®ä¿è¾“å‡ºæ˜¯åˆæ³•çš„ JSON æ ¼å¼ï¼Œä¸è¦åŒ…å« Markdown æ ‡è®°ã€‚
    """
    
    try:
        response = model.generate_content(prompt)
        clean_text = response.text.replace('```json', '').replace('```', '').strip()
        result = json.loads(clean_text)
        
        # ç®€å•éªŒè¯ç»“æ„
        if "structure" not in result or "translation" not in result:
             return {"error": "AIè¿”å›æ ¼å¼ä¸å®Œæ•´", "structure": []}
            
        return result
        
    except Exception as e:
        return {"error": f"AIåˆ†æå¤±è´¥: {e}", "structure": []}

# åˆ—åæ˜ å°„
COLUMN_MAPPING = {
    "word": "å•è¯",
    "reading": "è¯»éŸ³",
    "pos_meaning": "å“è¯ / æ„å‘³", 
    "grammar": "è¯­æ³•è¯´æ˜",
    "standard": "æ ‡å‡†å½¢å¼"
}

# --- 5. ç•Œé¢ UI ---
st.title("ğŸ‡¯ğŸ‡µ æ—¥è¯­è¯­æ³•ä¼´ä¾£ (Pro Max)")

st.session_state['user_id'] = st.sidebar.text_input("è¾“å…¥ä½ çš„æ˜µç§°:", value=st.session_state['user_id'])

# è¾“å…¥åŒº
with st.container():
    sentence = st.text_area("è¾“å…¥æ—¥è¯­:", height=80, placeholder="ä¾‹å¦‚ï¼šæ±ºã‚ã¡ã‚ƒã„ã¾ã™ã‹ã‚‰ã­")
    
    if st.button("âœ¨ AI æ·±åº¦è§£æ", type="primary"):
        if not sentence:
            st.warning("è¯·è¾“å…¥å¥å­")
        else:
            with st.spinner('AI è€å¸ˆæ­£åœ¨ç¿»è¯‘å’Œæ‹†è§£ (çº¦éœ€5ç§’)...'):
                ai_result = analyze_with_ai(sentence)
                
                # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
                if "error" in ai_result:
                    st.error(ai_result["error"])
                else:
                    # å†™å…¥ Google Sheets
                    save_record(sentence, ai_result)
                    
                    st.success("è§£æå®Œæˆï¼")
                    
                    # ğŸŒŸ 1. æ˜¾ç¤ºä¸­æ–‡ç¿»è¯‘ (æ–°å¢éœ€æ±‚)
                    st.markdown(f"""
                    <div class="translation-box">
                        <b>ğŸ‡¨ğŸ‡³ ä¸­æ–‡ç¿»è¯‘ï¼š</b><br>{ai_result.get('translation', '')}
                    </div>
                    """, unsafe_allow_html=True)

                    # ğŸŒŸ 2. æ˜¾ç¤ºè¡¨æ ¼ (è‡ªåŠ¨æ¢è¡Œ)
                    st.markdown("### ğŸ§© ç»“æ„æ‹†è§£")
                    df = pd.DataFrame(ai_result.get('structure', []))
                    if not df.empty:
                        df_display = df.rename(columns=COLUMN_MAPPING)
                        st.table(df_display)

                    # ğŸŒŸ 3. æ˜¾ç¤ºè¯­æ³•/æƒ¯ç”¨è¯­è¯¦è§£ (æ–°å¢éœ€æ±‚)
                    st.markdown(f"""
                    <div class="grammar-box">
                        <b>ğŸ’¡ è¯­æ³•ç¬”è®°ä¸æƒ¯ç”¨è¯­ï¼š</b><br>
                        {ai_result.get('nuances', 'æ— ç‰¹æ®Šè¯´æ˜').replace(chr(10), '<br>')}
                    </div>
                    """, unsafe_allow_html=True)

st.divider()

# --- 6. å­¦ä¹ è¶³è¿¹ (å«æœç´¢ä¸åˆ é™¤) ---
st.subheader("ğŸ“š å­¦ä¹ è¶³è¿¹")

# åŠ è½½æ•°æ®
history_df = load_history()

if not history_df.empty and 'timestamp' in history_df.columns:
    
    # ğŸŒŸ éœ€æ±‚äºŒï¼šæœç´¢æ¡†æ¶
    search_query = st.text_input("ğŸ” æœç´¢å†å²è®°å½• (è¾“å…¥å…³é”®è¯):", placeholder="è¾“å…¥æ—¥è¯­æˆ–ç¿»è¯‘å…³é”®è¯...")
    
    # æ‰§è¡Œè¿‡æ»¤
    if search_query:
        # æ¨¡ç³Šæœç´¢ï¼šåœ¨å¥å­åˆ—ä¸­æŸ¥æ‰¾
        filtered_df = history_df[history_df['sentence'].str.contains(search_query, case=False, na=False)]
    else:
        filtered_df = history_df

    # æ˜¾ç¤ºè®°å½•
    if filtered_df.empty:
        st.info("æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„è®°å½•ã€‚")
    else:
        # éå†æ˜¾ç¤º
        for index, item in filtered_df.iterrows():
            display_sentence = item['sentence'][:20] + '...' if len(item['sentence']) > 20 else item['sentence']
            
            # ä½¿ç”¨ expander åŒ…è£…å•æ¡è®°å½•
            with st.expander(f"ğŸ•’ {item['timestamp']} | {display_sentence}"):
                
                # å¸ƒå±€ï¼šå·¦è¾¹æ˜¾ç¤ºå†…å®¹ï¼Œå³è¾¹æ”¾åˆ é™¤æŒ‰é’®
                col1, col2 = st.columns([0.85, 0.15])
                
                with col1:
                    st.markdown(f"**åŸæ–‡ï¼š** {item['sentence']}")
                    
                    # è§£ææ•°æ®
                    data = item.get('data', {})
                    if data and "structure" in data:
                        # æ˜¾ç¤ºç¿»è¯‘
                        st.markdown(f"**ç¿»è¯‘ï¼š** {data.get('translation', 'æ— ')}")
                        
                        # æ˜¾ç¤ºè¡¨æ ¼
                        st.markdown("---")
                        df_hist = pd.DataFrame(data['structure'])
                        st.table(df_hist.rename(columns=COLUMN_MAPPING))
                        
                        # æ˜¾ç¤ºè¯­æ³•ç¬”è®°
                        if data.get('nuances'):
                             st.info(f"ğŸ’¡ ç¬”è®°ï¼š{data.get('nuances')}")
                    else:
                        st.warning("âš ï¸ æ—§æ•°æ®æˆ–è§£æå¤±è´¥ï¼Œæ— æ³•æ˜¾ç¤ºè¯¦ç»†å†…å®¹")

                # ğŸŒŸ éœ€æ±‚ä¸‰ï¼šåˆ é™¤åŠŸèƒ½
                with col2:
                    # ä¸ºæ¯ä¸ªæŒ‰é’®ç”Ÿæˆå”¯ä¸€çš„ key
                    btn_key = f"del_{item['timestamp']}"
                    if st.button("ğŸ—‘ï¸ åˆ é™¤", key=btn_key, type="secondary"):
                        with st.spinner("åˆ é™¤ä¸­..."):
                            if delete_record(item['timestamp']):
                                st.success("å·²åˆ é™¤")
                                time.sleep(1) # ç»™ä¸€ç‚¹æ—¶é—´è®©ç”¨æˆ·çœ‹åˆ°æç¤º
                                st.rerun() # åˆ·æ–°é¡µé¢
                            else:
                                st.error("åˆ é™¤å¤±è´¥")

else:
    st.info("è¿˜æ²¡æœ‰å­¦ä¹ è®°å½•ï¼Œå¿«å»è§£æç¬¬ä¸€å¥æ—¥è¯­å§ï¼")
